## Interpreter for the Functional Language L

This project represents an interpreter for a simplified functional programming language that borrows certain concepts from Lisp. The interpreter can analyze and execute code written in this language, providing support for regular expressions, functional operators, and flow control.

### Code Structure

The Parser: Implements the syntactic and semantic analysis of expressions in the source code. The parser transforms the code text into a data structure that the interpreter can use for execution.
Transformation of Regular Expressions into Nondeterministic Finite Automata (NFA): A module responsible for converting regular expressions into NFAs. This is achieved by applying appropriate algorithms for generating finite automata.
Construction of Deterministic Finite Automata (DFA): Modules responsible for constructing DFAs from the NFAs generated by regular expressions. This optimization process allows the interpreter to perform lexical analysis of the source code more efficiently.
The Lexer: Implements lexical analysis of the source code, transforming words in the code into tokens. This module uses the deterministic finite automaton to identify and classify the individual components of the program.
The Interpreter: Executes the source code by interpreting expressions and performing the operations specified by the user. This module uses the data structure generated by the parser to evaluate and execute instructions.

### Process Overview

Syntactic and Semantic Analysis: The parser analyzes the source code and verifies if it adheres to the language rules. If there are syntactic or semantic errors, corresponding messages are displayed.
Transformation of Regular Expressions: Regular expressions in the source code are transformed into NFAs, representing the corresponding nondeterministic finite automata.
Construction of Deterministic Finite Automata: The generated NFAs are converted into DFAs using the subset construction algorithm. This allows the interpreter to optimize lexical analysis.
Lexical Analysis: The lexer uses the generated DFA to divide words from the source code into tokens. Each token represents an individual component of the program, such as an identifier, an operator, or a constant.
Interpretation and Execution: The interpreter receives the tokens from the lexer and evaluates them to determine the corresponding action. It executes the instructions in the source code and displays results or error messages as needed.
